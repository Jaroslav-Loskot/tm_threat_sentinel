
-----

# 🤖 AI Threat Intelligence Bot

This project is an autonomous AI agent that monitors a Slack channel for potential security threats. It crawls posted URLs, analyzes their content against your internal infrastructure context, and provides real-time threat analysis directly in Slack.

## ✨ Core Features

  * **Real-time Slack Monitoring**: Continuously watches a specified Slack channel for new messages containing URLs.
  * **Web Content Crawling**: Uses Playwright to fetch and parse the full text content from posted links.
  * **Context-Aware AI Analysis**: Enriches the LLM prompt with a pre-processed list of your company's infrastructure (from a CSV/XLSX) to determine the specific relevance, impact, and severity of a threat.
  * **Unified LLM Connectivity**: Uses **LiteLLM** to connect to various LLM providers, with a primary connector built for **AWS Bedrock** (supporting Claude, Nova, and Titan embeddings).
  * **Automated Slack Reporting**: Posts a structured analysis (Summary, Severity, Relevance, Impact) as a reply in the original message's thread.
  * **Smart Alerting**:
      * Adds emoji reactions (e.g., 🔴, 🟡, 🟢) to the original message based on the analysis.
      * Sends a direct message (DM) to a predefined list of users for high-severity or high-relevance threats.

-----

## 🚀 How It Works

The bot operates through a continuous pipeline:

1.  **Monitor**: The `ChannelMonitorPipeline` (`main_threatintel.py`) runs in an infinite loop, polling the specified Slack channel.
2.  **Detect**: When a user posts a message containing a URL (and not from the bot itself), the bot detects it.
3.  **Crawl**: It triggers the `crawler_manager` to use Playwright to visit the URL and extract its text content.
4.  **Analyze**: The extracted text is sent to the `analyzer_manager`, which uses the `llm_connector` to call an AI model (like AWS Bedrock Claude).
5.  **Contextualize**: This is the key step. The AI prompt includes the article text *and* the condensed infrastructure context generated by `infrastructure_converter.py`. This allows the AI to answer questions like, "Is this CVE relevant to *our* stack (e.g., our specific database or external-facing services)?"
6.  **Report**: The AI's structured response is parsed and formatted into a clean Slack message.
7.  **Alert**: The bot posts the analysis in a thread, adds a severity reaction (e.g., 🔴 for `High` severity), and DMs the security team if the threat is critical.

-----

## 🛠️ Getting Started

### Prerequisites

  * Python 3.10+
  * `uv` (or `pip`) for package management
  * An AWS account with access to **Bedrock** models (e.g., Anthropic Claude).
  * A Slack Bot token with the required permissions (see below).

### Slack Bot Permissions

Your Slack App (Bot) will need the following OAuth scopes:

  * `channels:history`: Read messages in the channel.
  * `chat:write`: Post replies and send DMs.
  * `reactions:write`: Add emoji reactions.
  * `users:read`: Find users by ID (for DMs).
  * `users:read.email`: Find users by email (for DM alerts).

### Installation

1.  Clone the repository:

    ```bash
    git clone <your-repo-url>
    cd <your-repo-name>
    ```

2.  Install the dependencies:

    ```bash
    # Using uv
    uv pip install -r requirements.txt

    # Or using pip
    pip install -r requirements.txt
    ```

### Configuration

Create a `.env` file in the root of the project and fill it with your credentials.

```ini
# .env.example

ALERT_EMAILS="john.doe@email.com,alice@emial.com" #add multiple with ',' 
ALERT_THRESHOLD=1
POLL_INTERVAL=60 # in seconds
MAX_MESSAGE_AGE=24h

SLACK_BOT_TOKEN=
SLACK_CHANNEL_NAME=
SLACK_MESSAGE_LIMIT=10

PYTHONPATH=${workspaceFolder}

LITELLM_BASE_URL=
LITELLM_API_KEY=
LITELLM_MODEL=
```

-----

## ⚙️ Usage

There are two main steps to run the application.

### 1\. Prepare Infrastructure Context (One-time Step)

Before the bot can analyze threats effectively, it needs to know what infrastructure you run.

1.  Create an inventory of your infrastructure as a **CSV** or **XLSX** file. See `src/converters/infrastructure_converter.py` for the expected column names (e.g., `Product`, `Vendor`, `Product type`, `Accessibility`, `Context`).

2.  Place your file (e.g., `my_infra.xlsx`) in a known location.

3.  Run the conversion script to generate the context files for the LLM.

    ```bash
    # (Assuming your script is in src/scripts/convert_infrastructure.py)
    uv run python src/scripts/convert_infrastructure.py
    ```

    This script will read your spreadsheet, categorize your assets (e.g., `external_facing`, `databases`), and save the output to `data/infrastructure/processed/` as both JSON and a token-efficient `.txt` file. The bot will automatically load this context.

### 2\. Run the Bot

You can run the bot in development mode (with auto-reload) or production mode.

**Development Mode (with auto-reload):**

This command uses `watchfiles` (via `src/dev_autoreload.py`) to monitor your `.py` files and restart the bot automatically on any code changes.

```bash
uv run python src/dev_autoreload.py
```

**Note**: The `dev_autoreload.py` file may need to be updated to point to the correct main module (e.g., `target="uv run -m src.main_threatintel"`).

**Production Mode:**

This command runs the main application directly.

```bash
uv run python src/main_threatintel.py
```

Once running, the console will log `🚀 Starting ThreatMark Channel Monitor...`. You can now post a URL in your monitored Slack channel to test it.

-----

## 📁 Project Structure Overview

```
.
├── src
│   ├── adapters            # Connectors to external services (LiteLLM, Bedrock)
│   │   ├── llm_connector.py      # Main connector for AWS Bedrock (text, vision, embeddings)
│   │   └── litellm_connector.py  # (Alternative) LangChain-based LiteLLM connector
│   │
│   ├── converters            # Scripts to transform data formats
│   │   └── infrastructure_converter.py # Logic to convert Excel/CSV to LLM context
│   │
│   ├── pipelines             # Core business logic flows
│   │   ├── base_pipeline.py    # Abstract base class for pipelines
│   │   └── channel_monitor.py  # The main workflow (Monitor -> Crawl -> Analyze -> Post)
│   │
│   ├── services              # Managers for specific clients
│   │   ├── analyzer_manager.py # Orchestrates LLM analysis
│   │   ├── crawler_manager.py  # Orchestrates Playwright crawling
│   │   └── slack_manager.py    # Handles all Slack API interactions
│   │
│   ├── scripts               # Standalone, runnable utility scripts
│   │   └── convert_infrastructure.py # Entry point for the infrastructure converter
│   │
│   ├── utils                 # Common helper functions (file, path, slack)
│   │
│   ├── dev_autoreload.py     # Development server with hot-reloading
│   └── main_threatintel.py   # Main application entry point
│
└── tests                   # Unit and integration tests
    └── test_bedrock_llm.py   # Test for the Bedrock connector
```